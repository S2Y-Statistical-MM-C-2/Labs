[["index.html", "Lab 5 - Exploring relationships and understanding correlation 1 Welcome to Lab 5 1.1 Correlation coefficient", " Lab 5 - Exploring relationships and understanding correlation 1 Welcome to Lab 5 Intended Learning Outcomes: Produce scatterplots of report quality; Calculate and interpret the sample correlation coefficient; Fit linear regression models by using lm; Interpret estimates of model parameters. 1.1 Correlation coefficient In the lectures we learned how to assess the strength of a linear relationship between random variables using the correlation coefficient. The population correlation is a measure of the magnitude of the strength of the relationship between two random variables \\(X\\) and \\(Y\\), and is defined as \\[\\begin{equation} \\rho(X,Y) =\\frac{\\mathrm{Cov}(X,Y)}{\\sqrt{\\mathrm{Var}(X)\\mathrm{Var}(Y)}}, \\tag{1.1} \\end{equation}\\] and can be estimated by replacing each of \\(\\mathrm{Cov}(X,Y)\\), \\(\\mathrm{Var}(X)\\) and \\(\\mathrm{Var}(Y)\\) by their unbiased estimators to give \\[\\begin{equation} r = \\frac{S_{xy}}{\\sqrt{S_{xx}S_{yy}}} = \\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum_{i=1}^n(x_i-\\bar{x})^2\\sum_{i=1}^n(y_i-\\bar{y})^2}}, \\tag{1.2} \\end{equation}\\] the sample correlation coefficient (\\(-1 \\leq r \\leq 1\\)). Given a sample of data, we can assess the statistical significance of the observed correlations between variables in the wider population. To do this we perform a hypothesis test. "],["example-1-simple-linear-regression.html", "2 Example 1: Simple linear regression 2.1 Creating scatterplots 2.2 Sample correlation coefficient 2.3 Fitting a linear model", " 2 Example 1: Simple linear regression The admissions committee of a comprehensive state university selected at random the records of 200 second-semester freshmen. The results, first-semester college GPA and SAT scores, are stored in the data set Grades in the package PASWR. The admissions committee wants to study the relationship between first-semester college grade point average (gpa) and scholastic aptitude test (sat) scores. To open this data file, type: library(PASWR) Grades &lt;- Grades This will assign the data to the object Grades. A spreadsheet of the data can be viewed by typing: fix(GRADES) but note that you will need to close this window before trying to excute any further commands. The spreadsheet can also be viewed by clicking on the GRADES object in the Workspace (top right of the screen). 2.1 Creating scatterplots The relationship between gpa and sat scores can be examined by using a scatterplot. This code will produce the basic scatterplot of gpa (y-axis) against sat (x-axis): plot(gpa ~ sat, data = Grades) Figure 2.1: Scatterplot of gpa versus sat. There are several options for personalising plots. First of all, you should add sensible axis labels to the plot and a main title. For example, by typing: plot(gpa ~ sat, data = Grades, xlab = &quot;SAT score&quot;, ylab = &quot;GPA&quot;, main=&quot;Scatterplot of GPA versus SAT scores&quot;) Figure 2.2: Scatterplot of gpa versus sat with annotated axis labels. You can also edit the points by changing the symbol type, size and colour, such as plot(gpa ~ sat, data = Grades, xlab = &quot;SAT score&quot;, ylab = &quot;GPA&quot;, main = &quot;Scatterplot of GPA versus SAT scores&quot;, pch = 2, cex = 0.7, col = &quot;blue&quot;) The plotting character is determined by the pch argument, the size of the plotted characters by cex, and the colour by the col argument. DISCUSSION: Looking at your plot, what can we say about the relationship between gpa and sat? Is the relationship linear or non-linear? Is the relationship positive or negative? How strong is the relationship? 2.2 Sample correlation coefficient From the scatterplot, we can see a linear relationship between gpa and sat. To further assess the strength of linear relationship, sample correlation coefficient \\(r\\) may be calculated. Let's first calculate \\(r\\) by using R as a calculator: x &lt;- Grades$sat y &lt;- Grades$gpa x_mean &lt;- mean(x) y_mean &lt;- mean(y) r &lt;- sum((x-x_mean) * (y-y_mean)) / sqrt(sum((x-x_mean)^2)*sum((y-y_mean)^2)) r ## [1] 0.7491015 The correlation coefficient varies from a strong negative linear association \\(r=-1\\), to no LINEAR association \\(r=0\\), to a strong positive linear association \\(r=1\\). QUESTION: Which of the following is the correct interpretation of the correlation coefficient? 74.9% correlation would indicate a weak negative linear relationship between GPA and SAT scores. 74.9% correlation would indicate a strong negative linear relationship between GPA and SAT scores. 74.9% correlation would indicate a weak positive linear relationship between GPA and SAT scores. 74.9% correlation would indicate a strong positive linear relationship between GPA and SAT scores. In R we can compute the sample correlation coefficient more efficiently by using the built-in function cor(): cor(x=Grades$sat,y=Grades$gpa) ## [1] 0.7491015 2.3 Fitting a linear model To find the equation that best describes the relationship between gpa and sat, the lm (abbreviation for Linear Model) function can be used: model.lm&lt;- lm(gpa ~ sat, data = Grades) model.lm ## ## Call: ## lm(formula = gpa ~ sat, data = Grades) ## ## Coefficients: ## (Intercept) sat ## -1.192064 0.003094 This fits a simple linear regression model with the response variable gpa and the explanatory variable sat. From the R output, note down the equation of the fitted line that is given: (Enter your answers to 3 decimal places.) gpa = + sat This is the line of best fit, describing the effect of sat on gpa. QUESTION: Which of the following is the correct interpretation of the regression model? The intercept of the fitted line is -1.192, so for every unit increase in sat, we expect gpa to decrease by 1.192. The intercept of the fitted line is -1.192, so for every unit increase in gpa, we expect sat to decrease by 1.192. The slope coefficient of the fitted line is 0.0031, so for every unit increase in sat, we expect gpa to increase by 0.0031. The coefficient of the fitted line is 0.0031, so for every unit increase in gpa, we expect sat to increase by 0.0031. QUESTION: Use R to calculate the point estimate of the change in the mean GPA when the SAT score increases by 50 points. ANSWER = Solution coef(model.lm)[2]*50 ## sat ## 0.1547135 Plot of the data including the fitted line A plot of the data can be re-produced as before with the fitted line added using the abline command. This command uses the intercept and slope information from the fitted line saved in model.lm. This is done using: plot(gpa ~ sat, data = Grades, xlab = &quot;SAT score&quot;, ylab = &quot;GPA&quot;, main = &quot;Scatterplot of GPA versus SAT scores&quot;, pch=20) abline(model.lm) "],["exercise-1-multiple-linear-regression.html", "3 Exercise 1: Multiple linear regression 3.1 Exploratory analysis 3.2 Fitting a linear model", " 3 Exercise 1: Multiple linear regression Hydrostatic weighing, also known as underwater weighing or hydrodensitometry, is one of the most accurate ways to measure body fat. The body fat of 78 high school wrestlers was measured using three separate techniques, namely hydrostatic weighing, skin fold measurements and the Tanita body fat scale. The results are stored in the data set HSwrestler in the PASWR package. Read in the data using: library(PASWR) HSWRESTLER &lt;- HSwrestler The data set contains nine columns, described as follows: AGE: age of wrestler in years HT: height of wrestler in inches WT: weight of wrestler in pounds ABS: abdominal fat TRICEPS: tricep fat SUBSCAP: subscapular fat HWFAT: hydrostatic fat TANFAT: Tanita fat SKFAT: skin fat This can be seen by typing: names(HSWRESTLER) In this example, it is of interest to investigate how hydrostatic fat (HWFAT) is related to abdominal fat (ABS) and tricep fat (TRICEPS). 3.1 Exploratory analysis TASK 1 Produce scatterplots of HWFAT (y) against Lactic ABS (x), and HWFAT (y) against TRICEPS (x). Hint You can use plot() such as in the previous example with Grades. Or you can refer to previous weeks labs and use ggplot(). Describe the relationship between HWFAT (y), ABS (x) and TRICEPS. 3.2 Fitting a linear model In Example 1, the function lm() was used to find estimates for parameters of a simple linear regression model. The same function can be used for multiple linear regression models by specifying the explanatory variables on the right side of the tilde (~) operator inside the lm() function. To build a multiple linear regression model with hwfat as the response variable and abs and triceps as explanatory variables, type: lm(HWFAT ~ ABS + TRICEPS, data = HSWRESTLER) Note down the equation of the fitted line from that is given: HWFAT = + ABS + TRICEPS QUESTION: Interpret what each coefficient means. For every unit increase in abdominal fat, hydrostatic fat is expected to increasedecrease by 0.3370.5042.059 unit, regardless of tricep fatwhile holding tricep fat constant. For every unit increase in tricep fat, hydrostatic fat is expected to increasedecrease by 0.3370.5042.059 unit, regardless of abdominal fatwhile holding abdominal fat constant. "],["example-2-simulating-random-variables.html", "4 Example 2: Simulating random variables 4.1 Independent random variables 4.2 Correlated random variables", " 4 Example 2: Simulating random variables We can use R to generate random variables. Here we will generate two random variables, \\(X\\) and \\(Y\\), that are, or aren't, related to each other in some form. This can help us understand the relationship between two variables and how they may be correlated. 4.1 Independent random variables Let's start by first generating two random variables that are independent of one another. You have already been introduced to the normal distribution, where some random variable, \\(X\\), is centred at mean \\(\\mu\\), with variance \\(\\sigma^2\\), such that \\(X \\sim N(\\mu, \\sigma^2)\\). To generate random variables from the normal distribution we can use the rnorm command. For example, let's say we want to generate \\(n=30\\) samples from two random variables, \\(X\\) and \\(Y\\), each with mean \\(\\mu = 10\\), and standard deviation \\(\\sigma = 1\\), we can do this as follows: n &lt;- 30 mu &lt;- 10 sigma &lt;- 1 set.seed(1) y &lt;- rnorm(n, mean = mu, sd = sigma) x &lt;- rnorm(n, mean = mu, sd = sigma) Note: since we are generating random numbers it is best to use the command set.seed beforehand to be able to replicate the results. For example, if we first run the line set.seed(1), and then the above code, we will generate the same random variables x and y, and a different set if we change the seed value. This gives us our random variables \\(X\\) and \\(Y\\), generated independently of one another, and so we should expect to see no relationship between them. Using set.seed(1) to obtain \\(X\\) and \\(Y\\), a scatterplot of their relationship is shown in Figure 4.1. Figure 4.1: Scatterplots of independent random variables. QUESTION: What can we say about the relationship between \\(X\\) and \\(Y\\) from Figure 4.1? What can be said about the two boxplots in Figure 4.1? QUESTION: Use R as a calculator or the cor() function to calculate the correlation between the two variables. What does this value tell us about the their relationship? The sample correlation \\(r\\) = , suggesting a strongmoderateweakno linear relationship between \\(X\\) and \\(Y\\). Solution x_mean &lt;- mean(x) y_mean &lt;- mean(y) r &lt;- sum((x-x_mean) * (y-y_mean)) / sqrt(sum((x-x_mean)^2)*sum((y-y_mean)^2)) print(r) ## [1] 0.04866964 cor(x,y) ## [1] 0.04866964 4.2 Correlated random variables Let us now look at how to generate random variables that are correlated in some way. To do that we will need to obtain the covariance or correlation matrix, and generate the random variables from a multivariate normal distribution. The multivariate normal distribution is a generalisation of the normal distribution to higher dimensions, and as multivariate data analysis is not covered until Honours level we will simplify things a little. To generate correlated random variables we can use the mvrnorm command (load library(MASS)). This requires us to obtain the covariance matrix, \\(\\Sigma\\), explaining the relationship between our two random variables. As you will find out in 2X, the covariance is scale dependent, and as such, the correlation is often easier to use and interpret. We simplify things by generating random variables, \\(X\\) and \\(Y\\), such that their variances are the same and equal to one. Assuming \\(\\text{Var}(X) = \\text{Var}(Y) = 1\\), we can then see from formula (1.1) that \\[\\rho(X,Y) =\\frac{\\mathrm{Cov}(X,Y)}{\\sqrt{\\mathrm{Var}(X)\\mathrm{Var}(Y)}} = \\frac{\\mathrm{Cov}(X,Y)}{\\sqrt{1 \\cdot 1}} = \\mathrm{Cov}(X,Y),\\] that is, the correlation and covariance are the same. This now means that the covariance matrix, \\(\\Sigma\\), and the correlation matrix, \\(P\\), are now equivalent, such that, \\[\\Sigma = \\begin{bmatrix} \\text{Var}(X) &amp; \\text{Cov}(X, Y) \\\\ \\text{Cov}(X, Y) &amp; \\text{Var}(Y) \\end{bmatrix} = \\begin{bmatrix} 1 &amp; \\rho(X, Y) \\\\ \\rho(X, Y) &amp; 1 \\end{bmatrix} = P.\\] Now, let's say we want to generate two random variables, \\(X\\) and \\(Y\\), from a multivariate normal distribution, such that \\((X, Y) \\sim N(\\boldsymbol{\\mu}, \\Sigma)\\). This can be done using the mvrnorm command as follows: library(MASS) set.seed(1) n &lt;- 30 mu &lt;- c(10, 10) rho &lt;- 0.85 Sigma &lt;- matrix(rho, nrow = 2, ncol = 2) + diag(2) * (1 - rho) rand.vars &lt;- mvrnorm(n, mu = mu, Sigma = Sigma) x &lt;- rand.vars[, 1] y &lt;- rand.vars[, 2] Here we have generated \\(n = 30\\) random samples from a multivariate normal distribution for \\(X\\) and \\(Y\\), with mean vector \\(\\boldsymbol{\\mu}^\\top =\\begin{bmatrix} \\mu_X &amp; \\mu_Y \\end{bmatrix} = \\begin{bmatrix}10 &amp; 10 \\end{bmatrix}\\), and correlation matrix, \\(P\\), such that \\(\\rho(X, Y) = 0.85\\). Figure 4.2: Scatterplots of correlated random variables. QUESTION: What can we say about the relationship between \\(X\\) and \\(Y\\) from the scatterplot in Figure 4.2? Calculate the sample correlation coefficient, \\(r\\). Is this the same as the correlation parameter, \\(\\rho\\), used to generate the data? Solution The sample correlation coefficient will not be exactly the same as the correlation parameter since the simulated data are random samples from the true population. What happens with the sample correlation, \\(r\\), and the 'true' correlation, \\(\\rho\\), as the number of samples, \\(n\\), increases? Edit the R code to obtain a weak-to-moderate positive linear relationship between \\(X\\) and \\(Y\\). Use a scatterplot to examine this relationship, and use the cor command to see if the sample correlation matches that used to simulate the data. Generate two random variables that exhibit a moderate-to-strong negative linear relationship. Use a plot to display this relationship, and obtain an estimate of the sample correlation coefficient. "],["example-3-spurious-correlation.html", "5 Example 3: Spurious correlation 5.1 Investigating the relationship with scatterplot 5.2 Further analsyis with sample correlation coefficient 5.3 Spurious Correlation", " 5 Example 3: Spurious correlation Hollywood legend Nicholas Cage seems to have a problem. It appears that every time he releases a new film upon the world, many people drown by falling into pools of water. Coincidence? Or, are some of his films that bad? Data: Cage.csv Columns:               C1: Year Year of film releases               C2: NumFilms   Number of Nicholas Cage films released that year               C3: NumDrowns Number of people who drowned falling into pools that year To access the data, download the file Cage.csv from Moodle and make sure it is saved in an accessible file. The working directory of your RStudio Session should be set to that folder. Once this is done, read in the data using: Cage &lt;- read.csv(&quot;Cage.csv&quot;) 5.1 Investigating the relationship with scatterplot To investigate the relationship between the number of films released in any year against the number of people drowning we should make a scatterplot. TASK: Produce a scatterplot of NumDrowned against NumFilms with labels and a sensible title. Hint You can use plot() such as in the previous example with Grades. Or you can refer to previous weeks labs and use ggplot(). Solutions plot(NumDrowned ~ NumFilms, data = Cage, xlab = &quot;Number of films released per year&quot;, ylab = &quot;Number of people drowning per year&quot;, main=&quot;Scatterplot of the Number of People Drowning VS Number of Films Released Per Year&quot;, pch=20) 5.2 Further analsyis with sample correlation coefficient cor(x=Cage$NumFilms, y=Cage$NumDrowned) ## [1] 0.6660043 QUESTION: How could we interpret this result? The sample correlation coefficient is 0.666, indicating a weak positive linear relationship between NumDrowned and NumFilms. The sample correlation coefficient is 0.666, indicating a moderate positive linear relationship between NumDrowned and NumFilms. The sample correlation coefficient is 0.666, indicating a strong neagtive linear relationship between NumDrowned and NumFilms. The sample correlation coefficient is 0.666, indicating no significant linear relationship between NumDrowned and NumFilms. 5.3 Spurious Correlation Does this mean that Nicolas Cage films are causing drownings? Quite obviously, the answer to this would be no. This is only correlation not causation. In fact, this is an example of spurious correlation, where two variables that are not related to each other in any way, that is, they are independent, could be inferred as being related. The number of Nicholas Cage films released in a year is clearly not related to the number of drowning accidents in that same year, but if we just take our correlation analysis on face value, then we would think otherwise. Reference: Spurious Correlations, Tyler Vigen "],["exercise-2-identifying-relationships.html", "6 Exercise 2: Identifying relationships", " 6 Exercise 2: Identifying relationships If we had data for the following studies, determine whether fitting a regression model would be appropriate or produce meaningful results. If a regression model is appropriate, identify which variable is the response variable and which is the explanatory variable. A study investigated whether federal spending, on average, is higher or lower in countries with higher rates of poverty.        Regression model appropriate? YesNo        Federal spending: ExplanatoryResponseN/A        Poverty rates: ExplanatoryResponseN/A A study was conducted to determine whether surgery or chemotherapy results in higher survival rates for a certain type of cancer.        Regression model appropriate? YesNo        Type of treatment: ExplanatoryResponseN/A        Survival rates: ExplanatoryResponseN/A A study found that, overall, left-handed people die at a younger age than right-handed people.        Regression model appropriate? YesNo        Age of death: ExplanatoryResponseN/A        Left- or right-handed: ExplanatoryResponseN/A A study to determine if per capita cheese consumption is correlated with the number of people who died getting tangled in bed sheets.        Regression model appropriate? YesNo        Number of people who died getting tangled in bed sheets: ExplanatoryResponseN/A        Per capita cheese consumption: ExplanatoryResponseN/A An experiment was conducted to test the effects of sleep deprivation on human reaction times.        Regression model appropriate? YesNo        Hours of sleep: ExplanatoryResponseN/A        Reaction times: ExplanatoryResponseN/A A study was conducted in order to predict the GPA of university students given their high school GPA.        Regression model appropriate? YesNo        GPA of university students: ExplanatoryResponseN/A        High school GPA: ExplanatoryResponseN/A A company ran a study to find out if there is a significant relationship between its advertising expenditures and its sales volume.        Regression model appropriate? YesNo        Advertising expenditures: ExplanatoryResponseN/A        Sales volume: ExplanatoryResponseN/A A sample of insured drivers with similar insurance policies were randomly selected. Interest is in determining whether there is a significant relationship between driving experience and insurance premium.        Regression model appropriate? YesNo        Driving experience: ExplanatoryResponseN/A        Insurance premium: ExplanatoryResponseN/A A study was run to investigate if ice cream sales are correlated with murder rates in the US.        Regression model appropriate? YesNo        Murder rates: ExplanatoryResponseN/A        Ice cream sales: ExplanatoryResponseN/A "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
