---
title: "Lab 9 - Transformations and Assumptions"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
biblio-style: apalike
link-citations: yes
rmd_files: ["index.Rmd", "Example1.Rmd","Example2.Rmd", "Exercise1.Rmd", "Exercise2.Rmd"]

---

```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(webexercises)
library(tinytex)
library(dplyr)
library(knitr)
library(ggplot2)
library(tidyverse)
library(PASWR2)
library(MASS)
library(VGAM)
# RUBBER<- Rubber
# FERTILIZE <- FERTILIZE

```


```{r include=FALSE, echo=FALSE}
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

# Welcome to Lab 9!

Intended Learning Outcomes:

1. Produce residual plots and assess the assumptions of a linear model. 
2. Fit linear models with transformed variable. 

## Introduction variable transformations
The need to transform variables may arise during the exploratory analysis when you realize that your predictor(s) do not have a linear relationship with the response, or during assumption checking when the residuals do not meet assumptions. Either way, a transformation of the response variable, the predictors, or both response and predictors may be necessary.

Once the model has been fitted using a transformation, it is still possible to report the findings in the original scale but a back-transformation is necessary. How do I back-transform my data, you ask? Simply apply the inverse operation (inverse of the transformation) to your predictions.  

In this section, we will explore what transformations may be necessary in your model. 

## Root 
A root transformation is one where you take a root of the variable. For example, you may take the square or cubic root. In the case that a square root transformation may be needed, you can fit it in a model using:
```{r, eval = FALSE}
# Model without transformation
model <- lm(y ~ x)
# Model with transformation
model.root <- lm(y ~ I(x^0.5))
```

Recognizing the need for the transformation is important. We can perform a small simulation to give you a taste for a predictor in need of a square root transformation looks like. 
```{r, include = FALSE, eval = TRUE, warnings= FALSE, message = FALSE, echo = FALSE}
set.seed(123) # Ignore this line

# Simulate data from a simple linear model
n <- 100
beta_0 <- 1
beta_1 <- 2
x.trans <- runif(n, min = 0, max =10)
Y <- beta_0 + beta_1*x.trans + rnorm(n, 0, sd = 1)
x <- x.trans^2
```

```{r root, fig.cap="Left: Scatterplot of Y vs x in the original scale. Right: Scatterplot after the square-root transformation of $x$", fig.align='center'}
par(mfrow = c(1,2))
plot(Y~x, pch = 16, 
     main = "Original Scale")
plot(Y~I(x^0.5), pch = 16, 
    main = "After Square-root Transformation")

```
## Reciprocal
The reciprocal transformation of $x$ is the same as saying $\frac{1}{x}$ or $x^{-1}$. You can fit it in a model using:
```{r, eval = FALSE}
# Model without transformation
model <- lm(y ~ x)
# Model with transformation
model.root <- lm(y ~ I(x^-1))
```

But, what does the data needing a reciprocal transformation look like? 
```{r, include = FALSE, eval = TRUE, warnings= FALSE, message = FALSE, echo = FALSE}
set.seed(123) # Ignore this line

# Simulate data from a simple linear model
beta_0 <- 1
beta_1 <- 1.5
x.trans <- runif(n, min = 0, max =100)
Y <- beta_0 + beta_1*x.trans + rnorm(n, 0, sd = 5)
x <- 1/x.trans
```

```{r reciprocal, fig.cap="Left: Scatterplot of Y vs x in the original scale. Right: Scatterplot after the reciprocal transformation of $x$", fig.align='center'}
par(mfrow = c(1,2))
plot(Y~x, pch = 16, 
     main = "Original Scale")
plot(Y~I(x^-1), pch = 16, 
    main = "After Reciprocal Transformation")

```
## Quadratic
The quadratic transformation of $x$ is the same as saying $x^2$. It is the inverse of the square-root transformation. It it a subset of the power transformations. More generalised, it is $x^a$, where $a$ is anything. The reciprocal can also be thought of in this same category. 
```{r, eval = FALSE}
# Model without transformation
model <- lm(y ~ x)
# Model with transformation
model.root <- lm(y ~ I(x^2))
```

But, what does the data needing a reciprocal transformation look like? 
```{r, include = FALSE, eval = TRUE, warnings= FALSE, message = FALSE, echo = FALSE}
set.seed(123) # Ignore this line

# Simulate data from a simple linear model
n <- 100
beta_0 <- 1
beta_1 <- 2
x.trans <- runif(n, min = 0, max =50)
Y <- beta_0 + beta_1*x.trans + rnorm(n, 0, sd = 4)
x <- sqrt(x.trans)
```

```{r quadratic, fig.cap="Left: Scatterplot of Y vs x in the original scale. Right: Scatterplot after the quadratic transformation of $x$", fig.align='center'}
par(mfrow = c(1,2))
plot(Y~x, pch = 16, 
     main = "Original Scale")
plot(Y~I(x^2), pch = 16, 
    main = "After Quadratic Transformation")

```

## Logarithmic
Last but not least, the logarithmic transformation is equivalent to saying $ln(x)$, which in `R` is the same as `log(x)`. As a special feature, models that use logarithmic transformations have approximate explanations without back-transforming the variables.

When $x$ has been transformed with a natural log transformation, the change in the
$ln(x)$ is roughly equal to the change in $x$ provided the changes in $x$ are small. Consider
the figure below, which graphically illustrates how changing the x values 3 and 6 by 10%
corresponds to an approximate increase in $ln(x)$ of about $10\%$.

<center>
![Small change in $x$ gives a similar small change in $ln(x)$](Images/fig_logs.png){width=400px, height=300px}
</center>

But when do you know you need a transformation?

```{r, eval = FALSE}
# Model without transformation
model <- lm(y ~ x)
# Model with transformation
model.root <- lm(y ~ log(x))
```

```{r, include = FALSE, eval = TRUE, warnings= FALSE, message = FALSE, echo = FALSE}
set.seed(123) # Ignore this line

# Simulate data from a simple linear model
n <- 100
beta_0 <- 1
beta_1 <- 2
x.trans <- runif(n, min = 0, max =5)
Y <- beta_0 + beta_1*x.trans + rnorm(n, 0, sd = 1.5)
x <- exp(x.trans)
```

```{r log1, fig.cap="Left: Scatterplot of Y vs x in the original scale. Right: Scatterplot after the log transformation of $x$", fig.align='center'}
par(mfrow = c(1,2))
plot(Y~x, pch = 16, 
     main = "Original Scale")
plot(Y~log(x), pch = 16, 
    main = "After Log Transformation")

```
But sometimes, both the response and the predictor should be log-transformed. What does this look like?

```{r, include = FALSE, eval = TRUE, warnings= FALSE, message = FALSE, echo = FALSE}
set.seed(123) # Ignore this line

# Simulate data from a simple linear model
n <- 100
beta_0 <- 1
beta_1 <- 2
x.trans <- runif(n, min = 0, max =2)
Y.trans <- beta_0 + beta_1*x.trans + rnorm(n, 0, sd = 0.5)
x <- exp(x.trans)
Y <- exp(Y.trans)
```

```{r log2, fig.cap="Left: Scatterplot of Y vs x in the original scale. Right: Scatterplot after the quadratic transformation of $x$", fig.align='center'}
par(mfrow = c(1,2))
plot(Y~x, pch = 16, 
     main = "Original Scale")
plot(log(Y)~log(x), pch = 16, 
    main = "After Log Transformation")

```
The model is straight forward to fit with 
```{r, eval = FALSE}
# Model without transformation
model <- lm(y ~ x)
# Model with transformation
model.root <- lm(log(y) ~ log(x))
```

## Credit where credit is due

The labs in S2 incorporate and adapt materials from:

Ugarte, M. D., Militino, A. F., & Arnholt, A. T. (2008). [Probability and Statistics with R](https://ebookcentral.proquest.com/lib/gla/detail.action?docID=5338596). CRC press.

