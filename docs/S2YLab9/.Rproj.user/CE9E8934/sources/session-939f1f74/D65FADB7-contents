# Exercise 2: Log-transformation on $x$

Rossman (1994) collected information on life expectancy in various countries of the world and the densities of people per television set and of people per physician in those countries. Our focus is to identify how female life expectancy ($Y$, abbreviated to FLE) is related to the number of people per physician ($x$, abbreviated to PPP).

**Data:** `LifeExp.csv`

**Columns:**

|                       **C1:** `PPP` - umber of people per physician

|                       **C2:** `FLE` - female life expectancy

Read the data using
```{r}
life <- read.csv("LifeExp.csv")
```


Firstly, produce a scatterplot of FLE against PPP by typing:
```{r fig.cap="Scatterplot of female life expectancy versus the number of people per physician.", fig.align='center', out.width="70%"}
plot(FLE ~ PPP, data = life)
```

**DISCUSSION**: Looking at the plot, what can we say about the relationship between female life expectancy and the number of people per physician? Do we need to consider transformations? A transformation of the predictor variable(s) may be useful if there is a non-linear monotonic (i.e. entirely
non-increasing or entirely non-decreasing) trend in the data, and non-linearity is the only problem.
In other words, assumptions on the error term (i.e. independence, zero-mean, constant variance,
normality) should be met.

As the relationship appears to be non-linear, we apply log-transformation to the predictor variable. Transforming the values of $x$ might be the first thing to try if there is a non-linear monotonic (i.e. entirely non-increasing or entirely non-decreasing) trend in the data, and non-linearity is the only problem. In other words, model assumptions (i.e. independence, zero-mean, constant variance, normality) should be met. The scatterplot of female life expectancy against $\log$(PPP) is produced by typing:

```{r logX, fig.cap="Scatterplot of female life expectancy versus log(number of people per physician).", fig.align='center', out.width="70%"}
plot(FLE ~ log(PPP), data = life, xlab = "log(PPP)")
```

Figure \@ref(fig:logX) shows a linear trend after transforming $x$. Therefore, we will model the relationship between FLE and $\log$(PPP) using a simple linear regression model. The model is given as:
\[Y_i = \alpha + \beta \log(x_i) + \epsilon_i,\quad \epsilon_i \sim N(0,\sigma^2), \quad i = 1,\ldots, 37.\]

## Statistical analysis

A simple linear regression model can be fitted by using the `lm` command:

```{r}
Model1 <- lm(FLE ~ log(PPP), data = life)
```

The summary table and ANOVA table of this model can be produced by using `summary()` and `anova()`:
```{r}
summary(Model1)
anova(Model1)
```

```{r echo=FALSE, results='hide'}
x <- log(life$PPP)
y <- life$FLE
n_digits <- 2
x_mean <- round(mean(x),n_digits)
y_mean <- round(mean(y),n_digits)
S_xy <- round(sum((x-mean(x))*(y-mean(y))),n_digits)
S_xx <- round(sum((x-mean(x))^2),n_digits)
S_yy <- round(sum((y-mean(y))^2),n_digits)
print(c(x_mean, y_mean, S_xx, S_yy, S_xy))
```

## Assumption checking

As seen in previous labs, model assumptions can be assessed graphically by producing a plot of the residuals versus the fitted values and a normal probability plot (Q-Q plot) of the residuals. It is important to check the assumptions of your model are met before using it. 

```{r ResVsFitted, fig.cap="Standardised residuals versus fitted values plot from fitting a simple linear regression model to transformed variables.", fig.align='center'}
plot(rstandard(Model1) ~ fitted(Model1))
abline(h=0, lty=3, lwd=1.5)
```

```{r QQ-plot, fig.cap="Normal probability (Q-Q) plot from fitting a simple linear regression model to transformed variables.", fig.align='center'}
qqnorm(rstandard(Model1))
qqline(rstandard(Model1))
```

Figure \@ref(fig:ResVsFitted) displays the residual plots after fitting a simple linear regression model to the transformed variables. The points are fairly evenly scattered above and below the zero line, which suggests it is reasonable to assume that the random errors have mean zero. The vertical variation of the points seems to be small for small fitted values. However, there are also less points in this case. It would be preferable if more data are available. In the normal probability plot (Figure \@ref(fig:QQ-plot)), we see that points do not exactly lie on diagonal line. This indicates that the normality assumption may not necessarily be satisfied. The independence of the random errors seems to be reasonable since each point refers to a different country.

**QUESTIONS**:

(a) Using the following summary statistics, calculate the least squares estimates of $\alpha$ and $\beta$. Check your answers with the column of `Estimate` in the summary table.

\[\bar{x} = 7.18,\ \bar{y} = 70.51,\ S_{xx}=72.42,\ S_{yy}=2825.24,\ S_{xy}=-397.56\]

<!-- (*Enter your answer by rounding to two decimal places*) -->

<!-- $\hat{\alpha}$ = `r fitb(109.93)`  -->

<!-- $\hat{\beta}$ = `r fitb(c(-5.489644,-5.48964,-5.4896,-5.49,-5.5))` -->

`r hide("Hint")`
\[\hat{\alpha} = \bar{y} - \hat{\beta}\bar{x},\ 
  \hat{\beta}  = \frac{S_{xy}}{S_{xx}}\]
`r unhide()`
```{r echo=FALSE, results='hide'}
beta_hat <- S_xy/S_xx;beta_hat
alpha_hat <- y_mean - beta_hat*x_mean; alpha_hat
```

(b) Write down the equation of the fitted model. Based on it, comment on the least squares estimate of $\beta$ and predict the value of female life expectancy when the number of people per physician equals 4000. 

`r hide("Solution")`
The regression equation is
\[\text{FLE} = 109.95 - 5.49 \cdot \log(\text{PPP})\]

$\hat{\beta}$ can be interpreted as: if $\log(\text{PPP})$ increases by 1 unit, the expected female life expectancy decreases by 5.49. 

When predicting the value of the response for a new observation, we need to back transform the variable. For example, if the number of people per physician is 4000, the best prediction of female life expectancy is $109.95 - 5.49 \cdot \log(4000) \approx 64.42$.

`r unhide()`

(c) Use the summary statistics in (a) to complete the analysis of variance table below, i.e. finding the degrees of freedom, the sum of squares, the mean squared error, and the $F$-statistic. Check your answer with the `anova` output. 

Component    DF       Sum Sq (SS)    Mean Sq (MS)   F
-----------  -------  -------------  -------------  --------
Model              
Residual       
Total         

(d) What hypotheses are being examined by the $F$-statistic in the ANOVA table? By looking at its $p$-value, what can you conclude about the fitted model?

`r hide("Solution")`
The null and alternative hypotheses are:
H$_0$: $\beta=0$  &emsp; versus &emsp; H$_1$: $\beta \neq 0$
Note that $\alpha$ is not included in the hypothesis.

Since the $p$-value (from `Pr(>F)`) is less than 0.05, we reject the null hypothesis and conclude that $\log$(PPP) is useful in predicting FLE. 
`r unhide()`

(e) Compute and interpret the coefficient of determination, $R^2$. Check your answer with the term `Multiple R-squared` in the summary table.

`r hide("Hint")`
\[R^2 = 1-\frac{\text{RSS}}{\text{TSS}}\]
`r unhide()`

`r hide("Solution")`
\begin{equation*}
\begin{split}
R^2 &= 1-\frac{\text{RSS}}{\text{TSS}}\\
&=1-\frac{642.91}{2182.34+642.91}\\
&=0.772
\end{split}
\end{equation*}
The $R^2$ tells us the model provides a relatively adequate fit to the data with 77% of variability in FLE can be explained by this model.
`r unhide()`

<!-- (f) Comment on the strength of linear relationship between $\log$(PPP) and FLE.  -->
<!-- `r hide("Hint")` -->
<!-- The strength of a linear relationship can be quantified using the sample correlation coefficient. -->
<!-- `r unhide()` -->

<!-- `r hide("Solution")` -->
<!-- We could calculate the sample correlation coefficient $r$ based on its definition or use the fact that $r^2 = R^2$ in the case of simple linear regression (see Chapter 2, $\S$ 2.1) -->

<!-- Approach 1: based on the definition -->
<!-- \begin{equation*} -->
<!-- \begin{split} -->
<!-- r &=\frac{S_{xy}}{\sqrt{S_{xx}S_{yy}}}\\ -->
<!-- &=\frac{-397.56}{72.42\cdot 2825.24}\\ -->
<!-- &=-0.879 -->
<!-- \end{split} -->
<!-- \end{equation*} -->

<!-- Approach 2: use $r^2=R^2$ -->
<!-- \[|r|=\sqrt{R^2} = \sqrt{0.772}=0.879\] -->
<!-- Based on the scatterplot, we know that the relationship between $\log$(PPP) and FLE is negative, and thus $r=-0.879$. -->

<!-- Approach 3: use the command `cor` in `R` -->
<!-- ```{r} -->
<!-- cor(log(life$PPP),life$FLE) -->
<!-- ``` -->

<!-- The sample correlation coefficient of $-0.879$ tells us that there is a strong negative relationship between $\log$(PPP) and FLE. -->
<!-- `r unhide()` -->


