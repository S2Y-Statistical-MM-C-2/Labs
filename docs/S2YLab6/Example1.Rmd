# Example 1 - Modelling College Grades


In Lab 4, we looked at the `Grades` dataset from the `PASWR` package, which records the first-semester college GPA and SAT scores for 200 freshmen. The question of interest is to check whether there is a linear relationship between GPA and SAT scores. Last time, we viewed the data in scatterplots, built a linear model, and calculated correlation to learn more about the relationship between SAT and GPA scores. Today, we will formally assess if the SAT is a useful variable in predicting GPA.

To open the dataset, type:
```{r message=FALSE}
library(PASWR)
GRADES <- Grades
```

**TASK**: Build the simple linear regression model for how GPA scores change with SAT scores and print the model summary.

`r hide("Hint")`
Remember the function `lm(y~x, data=)`.
It will be helpful to save this output using `<-` for future analysis.
`r unhide()`

## Hypothsis Testing for Regression Models

We want to test whether there is a linear relationship between GPA and SAT scores at the \(\alpha = 0.10\) significance level. While this is automatically done in R, we will practice conducting the hypothesis test using the five-step procedure, during which you will become more familiar with the R output. 

**Step 1 - Hypotheses**

As we are interested in the predictive power of SAT, we will perform a hypothesis test on the slope of the model. Suppose the model has the form of $Y_i=\beta_0+\beta_1 x_i +\epsilon_i$.


$$H_0 : \beta_1 = 0 \quad \text{versus} \quad H_1 : \beta_1 \neq 0$$


`r hide("Learn More")` 
A regression equation with slope \(\beta_1 = 0\) would indicate no influence of \(x\) on \(y\). Thus, to assess whether $x$ is a useful predictor, we test if the slope is different from 0.
`r unhide()`



**Step 2 - Test statistic**

Looking at the model summary below, we find that the value of test statistic is \(\hat{\beta}_1 = 0.0031\).

```{r echo=FALSE}
Model<- lm(gpa ~ sat, data = GRADES)
summary(Model)
```

Assuming the assumptions of a linear model are satisfied then:
\[\hat{\beta}_1 \sim N(\beta_1, \sigma^2_{\hat{\beta}_1})\]


The standardised test statistic under the assumption that \(H_0\) is true and its distribution are:

\[\frac{\hat{\beta}_1-\beta_1}{s_{\hat{\beta}_1}} \sim t_{200-2}\]


**Step 3 - Rejection region calculations**

**Finding the rejection region**

Because the standardised test statistic is distributed \(t_{198}\) and \(H_1\) is a two-sided hypothesis, the rejection region is the \(|t_\text{obs}| > t_{1-\alpha;n-p} = t_{0.95;198}\).

The value of standardised test statistic is given in the R output as 15.912 (`t value` associated with the predictor `sat`). Let's verify this is correct: 

$$t_\text{obs}=\frac{\hat{\beta}_1-\beta_1}{s_{\hat{\beta}_1}} = \frac{0.0031-0}{0.0001945}=15.9117$$

$s_{\hat{\beta}_1}$ can be found by either looking at `Std. Error` associated with `sat`, or taking the square root of the (2,2) entry of the variance-covariance matrix of $\mathbf{s}^2_{\boldsymbol \beta}$:

```{r}
s2_beta <- vcov(Model) #the variance-covariance matrix
s2_beta
sqrt(s2_beta[2,2])
```

The critical value (the $t$-value that corresponds to the significance level of 0.01), $t_{0.95;198}$, can be found using:
```{r}
qt(0.95,198)
```

**Step 4 - Statistical Conclusion**

**QUESTION**: Based on the value of standardised test statistic and critical value, do we reject the null hypothesis?

`r hide("Solution")`

We reject \(H_0\) because the value of standardised test statistic is greater than the critical value and hence is in the rejection region, i.e. \(t_{obs} = 15.9117 \geq 1.6526\).
`r unhide()`

Alternatively, we can compute the $p$-value associated with this $t$-test, which is equal to \(2 \times \mathbb{P}(t_{0.95;198} \geq 15.9117)\).

For the area to the right of the observed value of standardised test statistic, use `lower.tail=FALSE`.
``` {r, eval=TRUE, echo=TRUE}
pvalue <- 2*pt(15.9117, 198, lower.tail = FALSE)
pvalue
```

This gives the $p$-value nearly 0.


**Step 5 - English conclusion**


**QUESTION**: What does the previoius statistical conclusion tell you about the relationship between `GPA` and `SAT` scores?
```{r, echo = FALSE}
mcq4 <- c("There is insufficient evidence to suggest a linear relationship between sat and gpa.", "There is sufficient evidence to suggest a non-linear relationship between
sat and gpa.", answer ="There is sufficient evidence to suggest a linear relationship between sat and gpa.", 
"We cannot conclude if there is sufficient evidence to suggest a linear relationship between sat and gpa.")
```
`r longmcq(mcq4)`


## Confidence intervals for model parameters

We will practice constructing 90% confidence intervals for \(\beta_0\) and \(\beta_1\).

These 90% CIs will take the format of \(\left( \hat{\beta}_k - t_{0.95;198} \cdot s_{\hat{\beta}_k} \text{ },\text{ } \hat{\beta}_k + t_{0.95;198} \cdot s_{\hat{\beta}_k}\right)\)

The parameter estimates \(\hat{\beta}_k\) can be found in the model summary and their standard errors \(s_{\hat{\beta}_k}\) can be found from the variance-covariance matrix or from the model summary as well.

```{r}
b0 <- coef(summary(Model))[1, 1]
s.b0 <- coef(summary(Model))[1, 2] #or s.bo <- sqrt(vcov(Model)[1,1])
b1 <- coef(summary(Model))[2, 1]
s.b1 <- coef(summary(Model))[2, 2] #or s.bo <- sqrt(vcov(Model)[2.2])
ct <- qt(1 - 0.1/2, 198) # alpha = 0.10
CI.B0 <- b0 + c(-1, 1) * ct * s.b0
CI.B1 <- b1 + c(-1, 1) * ct * s.b1
CI.B0
CI.B1
```

R also has a built-in function `confint` to compute the confidence interval:

```{r}
confint(Model, level = 0.9)
```