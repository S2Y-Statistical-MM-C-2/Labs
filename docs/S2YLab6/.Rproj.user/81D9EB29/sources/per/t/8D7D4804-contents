# Example 1: Cherry trees

This data set has been looked at in the lectures. The main question of interest is how to model the relationship between log(volume) ($y$) and log(diameter) ($x_1$) and log(height) ($x_2$), using data from 31 cherry trees. To model the relationship we decided to go with the multiple linear regression model

\begin{equation}
Y_i = \alpha + \beta x_{1i} + \gamma x_{2i} + \epsilon_i, \quad \epsilon_i \sim N(0, \sigma^2), \quad i=1,\ldots,31 (\#eq:TreesMLR)
\end{equation}

## Exploratory analysis

A matrix plot with scatterplots between each pair of variables can be used to gain an initial impression. This can be produced by using the following command in `R`:

```{r TreesPlot1, fig.align='center',fig.cap="Scatterplot displaying the relationships between the three variables."}
trees1 <- read.csv("trees1.csv")
pairs(trees1, lower.panel = NULL)
```

The argument `lower.panel = NULL` only displays the top diagonal of the matrix which ensures the response of log(volume) is on the y-axis of the plots. It may be more appropriate to use `upper.panel = NULL` depending on the position of the response variable in the dataframe. Figure \@ref(fig:TreesPlot1) shows the relationships between the three variables.

**DISCUSSION**: What can we say about the relationships between the three variables?

## Statistical analysis

We now fit the multiple linear regression model in formula \@ref(eq:TreesMLR) in `R` using the following command:

```{r}
Model3 <- lm(logvol ~ logdiam + loght, data = trees1)
```

and produce residual plots to graphically assess the assumptions of the linear model using:

```{r TreesRes, fig.align='center',fig.cap="Residuals vs. fitted values (left) and normal Q-Q plot (right) from model (2.1) fitted to `trees`.", fig.width=9}
par(mfrow=c(1,2))
plot(rstandard(Model3) ~ fitted(Model3))
abline(h=0, lty=3)
qqnorm(rstandard(Model3))
qqline(rstandard(Model3))
```

**DISCUSSION**: Based on the residual plots, comment on whether the assumptions of normal linear models seem to hold or not. 

### Regression output

We can now examine the regression output by typing:
```{r}
summary(Model3)
```

**QUESTION**: Which of the following comments is most appropriate to describe how well the model fits the data?
`r longmcq(c("Based on the R^2, 97.77% of the variation in the log volume of the cherry trees is accounted for by the linear model with log diameter and log height as predictors, and hence the model provides a very good fit to the data.", answer="Based on the adjusted R^2, 97.61% of the variation in the log volume of the cherry trees is accounted for by the linear model with log diameter and log height as predictors, and hence the model provides a very good fit to the data.", "The p-value for both logdiam and loght are less than 0.05, and hence the model provides a very good fit to the data.", "The p-value for F-test is less than 0.05, and hence the model provides a very good fit to the data."))`
<br>

The analysis of variance (ANOVA) table can also be obtained using:
```{r}
anova(Model3)
```

### Hypothesis testing
The hypotheses being tested for each of the parameters here are:

$$H_0: \beta = 0 \ /\ \gamma = 0 \quad \text{vs.} \quad H_1: \beta \ne 0 \ / \ \gamma \ne 0$$

Since the $p$-values for `logdiam` and `loght` are both $< 0.001$ (indicated by the significance codes in `R` '***'), and hence $< 0.05$, the null hypothesis $H_0$ is rejected and we conclude that log(diameter) is a statistically significant predictor of log(volume) in addition to log(height), and log(height) is a statistically significant predictor of log(volume) in addition to log(diameter).

### Confidence interval for $\mathbf{b}^\top \boldsymbol\beta$
From lectures, the formula for a 95% confidence interval for a linear combination of the model parameters is

\[ \mathbf{b}^\top\boldsymbol{\hat{\beta}}\pm t\left(n-p; 0.975\right)\cdot e.s.e(\mathbf{b}^\top \hat{\boldsymbol\beta})\]

or, more explicitly,

\[ \mathbf{b}^\top\boldsymbol{\hat{\beta}}\pm t\left(n-p; 0.975\right)\sqrt{\frac{\text{RSS}}{n-p}\mathbf{b}^\top(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{b}}\]

A 95% confidence interval for $\beta$, the coefficient of log(diameter), can be formed by taking the vector $\mathbf{b}$ to be

$$\mathbf{b} = \begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix}.$$

From the regression output, we know $\hat{\beta}$ (the coefficient, estimate of the model parameter) and the estimated standard error for the parameter, which are 1.98265 and 0.07501 respectively. 

We could also verify the result of estimated standard error. We 
know that

$$\text{RSS} = 0.1855 \quad\quad\quad\quad\quad n-p = 31 - 3 = 28,$$
and $(\mathbf{X}^\top\mathbf{X})^{-1}$ can be computed by using
```{r eval=FALSE}
X <- model.matrix(~ logdiam + loght, data = trees1)
solve(t(X) %*% X)
```

which gives
```{r echo=FALSE, results="hide"}
X <- model.matrix(~ logdiam + loght, data = trees1)
solve(t(X) %*% X)
```

\[(\mathbf{X}^\top\mathbf{X})^{-1} = \begin{bmatrix}
96.572067 & 3.1392672 & -24.165092\\
3.139267 & 0.8494646 & -1.227489\\
-24.165092 & -1.2274894 & 6.309851
\end{bmatrix}\]

Therefore, the estimated standard error for $\beta$ is given by
```{r}
sqrt(0.1855 / 28 * 0.8494646)
```

To calculate the confidence interval, it remains to find the 0.975th quantile of the $t$-distribution with 28 degrees of freedom, and we do this in `R` as follows:
```{r}
qt(p = 0.975, df = 28)
```

**Calculations**

Therefore, a 95% confidence interval for $\beta$ can be found by computing:
```{r}
1.98265 + 2.048407 * 0.07501
1.98265 - 2.048407 * 0.07501
```


Hence a 95% confidence interval for the coefficient of log(diameter) is (1.83, 2.14). As this interval does not contain 0, we conclude that the predictor log(diameter) makes a statistically significant contribution in addition to the predictor log(height) in explaining the variability in log(volume). Therefore log(diameter) is retained in the model, in addition to log(height). The coefficient for log(diameter) is highly likely to lie between 1.83 and 2.14.

These intervals can be computed for all estimated parameters simultaneously in \texttt{R} using the following command:
```{r}
confint(Model3)
```

**QUESTION**: Calculate a 95% confidence interval for the coefficient $\gamma$ using the general formula for a confidence interval; check the result is same as the `R` output returned from `confint(Model3)`. Interpret this interval. 

`r hide("Solution")`
```{r eval=FALSE}
1.11712 + 2.048407 * 0.20444
1.11712 - 2.048407 * 0.20444

#The estimated standard error is computed as
sqrt(0.1855 / 28 * 6.309851)
```
We can check this against the answers in `confint()` results:
0.698353  1.535894

A 95% confidence interval for the coefficient of log(height) is (0.70, 1.54). As this interval does not contain 0, we conclude that the predictor log(height) makes a statistically significant contribution in addition to the predictor log(diameter) in explaining the variability in log(volume). Therefore log(height) is retained in the model, in addition to log(diameter). The coefficient for log(height) is highly likely to lie between 0.70 and 1.54.
`r unhide()`

### Confidence interval for the population mean response and prediction interval for a future response

Once we have fitted the model of interest it may also be useful to compute further confidence and prediction intervals from the fitted model. For example,

(a) a 95% confidence interval for the population mean response; and
(b) a 95% prediction interval for the response of an individual member of the population.

**Questions**

1. Suppose that we consider a population of cherry trees for which the log(diameter) is 2.4 and the log(height) is 4.3. Provide a 95% confidence interval for the mean log(volume) in this population of cherry trees. Interpret the interval.
2. Suppose, now, that we wish to obtain a 95% prediction interval for an individual cherry tree in the population which has a log(diameter) of 2.4 and a log(height) of 4.3. Interpret the interval.

We use `R` to compute the required intervals.

**Question 1 - 95% confidence interval for the population mean:**

```{r}
predframe <- data.frame(logdiam = 2.4, loght = 4.3)
predict(Model3, int = "c", newdata = predframe)
```

The `data.frame` command creates a table; each column represents one variable and each row contains one set of values from each column. The `predict` command can produce both a confidence interval and a prediction interval. To obtain a confidence interval we use the argument `int = "c"`.

Therefore we conclude that in a population of cherry trees for which the log(diameter) is 2.4 and the log(height) is 4.3 it is highly likely that the log(volume) would lie, on average, somewhere between 2.89 and 2.97.

**Question 2 - 95% prediction interval for a future tree:**
```{r}
predict(Model3, int = "p", newdata = predframe)
```

The argument `int = "p"` in the `predict` command provides a prediction interval based on the specified values in the new dataframe `predframe`. Therefore if a cherry tree with a log(diameter) of 2.4 and a log(height) of 4.3 were selected randomly from the population of cherry trees, it is highly likely that it would have a log volume of somewhere between 2.76 and 3.10. Comparing with the 95% confidence interval, the 95% prediction interval has a wider range. 

